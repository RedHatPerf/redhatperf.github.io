<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=" Learn about what is coordinated omission
"><title>Coordinated Omission</title><link rel=canonical href=http://example.org/post/coordinated-omission/><link rel=stylesheet href=/scss/style.min.c3ce6bc8f68d8b32c7079ef6cf45fdf24e00003418a0955c1897115bd2ea7f1c.css><meta property="og:title" content="Coordinated Omission"><meta property="og:description" content=" Learn about what is coordinated omission
"><meta property="og:url" content="http://example.org/post/coordinated-omission/"><meta property="og:site_name" content="Red Hat App Services Performance Team"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2022-11-16T00:00:00+00:00"><meta property="article:modified_time" content="2022-11-16T00:00:00+00:00"><meta property="og:image" content="http://example.org/post/coordinated-omission/coordinated-omission-cumulative-wait-time.png"><meta name=twitter:title content="Coordinated Omission"><meta name=twitter:description content=" Learn about what is coordinated omission
"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://example.org/post/coordinated-omission/coordinated-omission-cumulative-wait-time.png"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.setItem(e,"light")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/redHatLogo_hu1c053dbd2674ef6a4ce5cecbb630113c_5104_300x0_resize_q75_box.jpeg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Red Hat App Services Performance Team</a></h1><h2 class=site-description></h2></div></header><ol class=social-menu><li><a href=https://github.com/RedHatPerf/ target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/page/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/page/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/page/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><div class=menu-bottom-section></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/post/coordinated-omission/><img src=/post/coordinated-omission/coordinated-omission-cumulative-wait-time_hu97636a6d6452f8d98e3a591576d9d311_212721_800x0_resize_box_3.png srcset="/post/coordinated-omission/coordinated-omission-cumulative-wait-time_hu97636a6d6452f8d98e3a591576d9d311_212721_800x0_resize_box_3.png 800w, /post/coordinated-omission/coordinated-omission-cumulative-wait-time_hu97636a6d6452f8d98e3a591576d9d311_212721_1600x0_resize_box_3.png 1600w" width=800 height=317 loading=lazy alt="Featured image of post Coordinated Omission"></a></div><div class=article-details><header class=article-category><a href=/categories/performance/>performance</a>
<a href=/categories/benchmarking/>benchmarking</a>
<a href=/categories/methodology/>methodology</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/post/coordinated-omission/>Coordinated Omission</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Nov 16, 2022</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>15 minute read</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><a href=http://example.org/authors/john-ohara/>John O'Hara</a></div></footer></div></header><section class=article-content><div class=paragraph><p>Learn about Coordinated Omission, the root cause and its effects. After reading this post you should be able to answer questions such as "What is Coordinated Omission?", "How does it effect benchmark results", "How can we design a load test that does not suffer from coordinated omission" and "does my tool suffer from the coordinated omission problem?"</p></div><div class=sect1><h2 id=_tldr>Tl;dr</h2><div class=sectionbody><div class=paragraph><p>Coordinated Omission occurs when the load generator we choose is not able to accurately create a workload representative of real world traffic whilst load testing a remote service.</p></div><div class=paragraph><p>There is a "Coordination" from the System Under Test applying indirect back pressure to the load driver, that causes the load driver to "Omit" any number of valid results. The System Under Test can blocks the load generator, severely skewing it’s measurements.</p></div><div class=paragraph><p>Response time metrics measured with tools that suffer from Coordinated Omission are far from misleading, they are wrong. The worst part is, the load generator can not detect or inform users that the results are incorrect.</p></div><div class=paragraph><p>Using tools such as <a href=https://hyperfoil.io/>Hyperfoil</a>, you can be sure that any response time metrics it captures are accurate; or, if it detects back-pressure from the System Under Test, it will record and report the unintended back-pressure.</p></div></div></div><div class=sect1><h2 id=_tell_me_about_this_coordinated_omission_thingy>Tell me about this Coordinated Omission thingy!</h2><div class=sectionbody><div class=paragraph><p><em>Coordinated Omission</em> is a term that has been in circulation for a while now. There are many articles that describe; for more detailed explanations of coordinated omission, please take a look at <a href=#_further_reading>Further Reading</a>.</p></div><div class=paragraph><p>Before exploring the nuances of coordinated omission, lets get clear in our minds what it is we are trying to do when we are measuring system "response time".</p></div><div class=paragraph><p>Imagine a scenario where we run a call center for a building materials trade counter (<strong>Building Star Trade Supplies Inc</strong>)</p></div><div class=paragraph><p>Our tag line is "<strong><em>Building Star Trade Supplies Inc: the best in the world for all your building supply needs!</em></strong>"</p></div><div class=paragraph><p>To improve customer experience, we want to reduce the time it takes for our customers to place an order. The faster customers can place an order, the happier they are, and the faster we can build a world beating business!</p></div><div class=paragraph><p>What do we need to do; measure how long it takes to place a telephone order through our switchboard.</p></div><div class=paragraph><p>If it takes longer than 1 minute to place an order we will start to loose market share to our rivals <em>Prime Materials Supplies</em>.</p></div><div class=sect2><h3 id=_a_typical_interaction>A typical interaction</h3><div class="imageblock right text-center"><div class=content><img src=customer-interaction.png alt=Interaction width=400 height=400></div></div><div class=paragraph><p>Typically a customer calls the call center, is put through to an operator, where the operator checks stock levels, raises a new order and confirms with the customer before terminating tha call.</p></div></div><div class=sect2><h3 id=_how_long_does_it_take_to_place_an_order>How long does it take to place an order?</h3><div class=imageblock><div class=content><img src=coordinated-omission-placeOrder.png alt="Order timeline"></div></div><div class=paragraph><p>There are 2 main components in the time taken to place the order;</p></div><div class=ulist><ul><li><p>the <strong>"Wait Time"</strong> the customer was being held in the switchboard queue before being put through the operator</p></li><li><p>The <strong>"Service Time"</strong> it took for the operator to process the customer request</p></li></ul></div><div class=paragraph><p>From the customers point-of-view, the total <strong>"Order Time"</strong> (i.e. the time taken to place the order) is ;</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>"Order Time" = "Wait Time" + "Service Time"</strong></p></div><div class=paragraph><p>To measure the performance of our call center, we need to measure the total "Order Time".</p></div><div class=paragraph><p><strong>If it only takes a single operator 30 seconds to process an order request, but customers are waiting on average 30 minutes to be connected to them, the customer experience is poor</strong></p></div></td></tr></tbody></table></div></div></div></div></div><div class=sect1><h2 id=_what_does_a_call_center_have_to_do_with_my_web_service>What does a call center have to do with my Web Service?!?</h2><div class=sectionbody><div class=paragraph><p>There are a lot of similarities between a call center and a Web Service.</p></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content><div class=paragraph><p>Any number of <em>customers</em> (<strong>clients</strong>) can <em>call</em> (<strong>tcp_socket::open</strong>) our <em>switchboard</em> (<strong>web service</strong>), where an <em>operator</em> (<strong>thread</strong>) will process the <em>enquiry</em> (<strong>request</strong>), interacting with multiple <em>systems</em> (<strong>backend services</strong>) before confirming an <em>order</em> (<strong>response</strong>) and terminating the <em>call</em> (<strong>tcp_socket::close</strong>).</p></div><div class="imageblock right text-center"><div class=content><img src=terminology_equivalence.png alt="Terminology Equivalence"></div></div></td></tr></tbody></table></div></div><div class=paragraph><p>Typically for us developers of web services; before we push our changes into production, we want to know how it will scale or perform under sustained client load. So, we build a benchmark, take some measurements and deploy depending on if we see acceptable performance.</p></div><div class=paragraph><p>But <strong>how</strong> do we measure performance of a web service? What decisions do we take, and how does this impact our confidence in how our web service performs.</p></div></div></div><div class=sect1><h2 id=_measuring_system_performance>Measuring System performance</h2><div class=sectionbody><div class=paragraph><p>So, you’ve been tasked with ensuring the application can handle production workload. The checklist typically looks something like;</p></div><div class="ulist checklist"><ul class=checklist><li><p>✓ pick a load generation tool</p></li><li><p>✓ setup benchmarking environment</p></li><li><p>✓ run load generation tool against test environment</p></li><li><p>✓ ensure the system response times are within required SLA’s</p></li><li><p>❏ ship it!</p></li></ul></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>The first step is crucial! : Picking a load generation tool that models reality is vital in shipping a product that behaves they way you expecct it to</strong></p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_modelling_the_real_world>Modelling the real world</h2><div class=sectionbody><div class=paragraph><p>Let’s go back to our <strong>Building Star Trade Supplies Inc</strong>. In order to improve customer experience, we have built a brand new call center <strong>BSTSI-callHandler-2.0</strong>!!</p></div><div class=paragraph><p>We have tested to make sure the call center works (<strong>functional testing</strong>); but before we start taking customers calls there, we need to ensure that it is more efficient (<strong>load testing</strong>) than <strong>BSTSI-callHandler-0.1.BETA</strong>.</p></div><div class=paragraph><p>For this work, we need to design a test that models the real world!</p></div><div class=sect2><h3 id=_designing_the_load_test>Designing the "load" test</h3><div class=paragraph><p>Our SLA for our call center stipulates that we need to be able to;</p></div><div class=ulist><ul><li><p>Process <strong>20 orders per minute</strong></p></li><li><p>Customers must spend <strong>on average less than 1 minutes</strong> on the phone placing an order.</p></li><li><p>99% of customers should be able to place an order within <strong>2 minutes</strong></p></li></ul></div><div class=paragraph><p>So, lets bring in a number of dummy customers (<strong>clients</strong>) that will ring the call center and place fictitious orders. We can measure how long it takes for each dummy customer to place and order.</p></div><div class=paragraph><p>To meet the SLA, we need to be able to process <strong>20 orders per minute</strong> (<strong>throughput</strong>) with the average telephone call taking less than <strong>1 minute</strong> (<strong>mean response time</strong>).</p></div></div><div class=sect2><h3 id=_first_attempt>First attempt</h3><div class="imageblock right text-center"><div class=content><img src=firstTest.png alt="First Test" width=400 height=400></div></div><div class="olist arabic"><ol class=arabic><li><p>Each tester is given their own phone and a list of orders to place</p></li><li><p>The tester calls the new call center and places an order</p></li><li><p>After the call terminates, the tester checks the phone screen to see how long the call took</p></li><li><p>Call durations are logged for each order</p></li><li><p>After all the testers have run through their list of dummy orders. The call times for all the testers are collated</p></li></ol></div><div class=paragraph><p>After reviewing the call logs, we found the average call duration was <strong>36 seconds</strong>. This within our SLA limit of 1 minute, <strong>SHIP IT!</strong></p></div></div><div class=sect2><h3 id=_ship_it>Ship It!!</h3><div class="imageblock right text-center"><div class=content><img src=realworld.png alt="Real World" width=400 height=400></div></div><div class=paragraph><p>Fairly soon after opening <strong>BSTSI-callHandler-2.0</strong>, negative reviews start appearing. Some people are frustrated that they can not quickly get through to place an order. And it is not just one person! there are a few disgruntled customers.</p></div></div><div class=sect2><h3 id=_what_went_wrong>What went wrong?</h3><div class=paragraph><p><strong>Our test had some fundamental flaws</strong>. While everything appeared to provide us with the data to give us confidence about how the call center would perform, we were not quite modelling how calls would arrive <strong>in the real world</strong>.</p></div><div class=paragraph><p>Each tester had been given their own phone and a list of orders to place. This puts some limits on the test;</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class="olist arabic"><ol class=arabic><li><p><strong>Testers can only place one order at a time!</strong></p></li><li><p><strong>Testers are blocked</strong> from placing any more orders until their current order is placed.</p></li><li><p>In the real world there are many more customers, <strong>each with their own phone</strong></p></li><li><p>In the real world, <strong>customers enquiries arrive at different, random times, often in parallel</strong>.</p></li></ol></div></td></tr></tbody></table></div></div><div class=paragraph><p>In addition to to the test design problems above, in the real world there are <strong>hiccups</strong>. For example, in our call center there are Lunch breaks, fire alarms, computer systems crash etc.</p></div></div><div class=sect2><h3 id=_how_does_a_hiccup_effect_our_call_center_performance>How does a Hiccup effect our call center performance?</h3><div class=paragraph><p>We have our imaginary call center, now lets have an imaginary outage!</p></div><div id=img-dilbert-token-ring class="imageblock right text-center"><div class=content><a class=image href=https://dilbert.com/strip/1996-05-02><img src=dilbert_token_ring.gif alt="Dilbert Token Ring"></a></div><div class=title>Figure 1. <a href=https://dilbert.com/strip/1996-05-02 class=bare>https://dilbert.com/strip/1996-05-02</a></div></div><div class=paragraph><p>Someone in the server room has rolled over a network cable and accidentally severed it, finding a new cable and wiring the server back into the switch takes 10 mins. All the backend systems were out for 10 minutes, tying up the operators until the backend systems come back online.</p></div></div><div class=sect2><h3 id=_lets_do_some_math>Lets do some Math!</h3><div class=paragraph><p>Lets make some assumptions about our imaginary call center, with its imaginary outage;</p></div><div class=ulist><ul><li><p>testers will make <strong>1,000 new orders</strong>.</p></li><li><p>we have <strong>10 testers</strong>.</p></li><li><p>the call center should be handling 20 calls per minutes (i.e. 2x 30s calls per tester). The <strong>arrival rate is 20 calls per minute</strong></p></li><li><p>the maximum call handle rate (max throughput) of the call center is 60 calls per minutes. I.e. the <strong>maximum processing rate is 60 calls per minutes</strong></p></li><li><p>any <strong>backlog does not effect the service time</strong> (in reality this is not true, but brevity we will making this assumption)</p></li><li><p>our call center has a <strong>10 minute hiccup</strong> in the middle of the test.</p></li><li><p>all calls are processed, the <strong>dropout rate is 0</strong></p></li><li><p>each order takes a deterministic <strong>30 seconds</strong> to complete. (<strong>service time = 0.5min</strong>)</p></li><li><p>in the time before the outage, all calls are handled immediatley (<strong>waiting time = 0min</strong>)</p></li><li><p>the queue is a First-In-First-Out (FIFO) queue</p></li><li><p>the queue is infinitely sized</p></li></ul></div><div class=paragraph><p>What does this do the to summary statistics? A 10 minute Hiccup <em>during our tests</em> would have been observed like this by the <strong>testers</strong>;</p></div><div class=imageblock><div class=content><img src=coordinated-omission-blocked-wait-time.png alt="Blocked Wait Time"></div></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content><div class=paragraph><p>The <strong>Average Call Duration measured during Testing was 0.6 minutes (0min 36sec)</strong></p></div></td></tr></tbody></table></div></div><div class=paragraph><p>Whereas, <em>in reality</em>, a 10 minutes Hiccup will be observed like this by our <strong>customers</strong>;</p></div><div class=imageblock><div class=content><img src=coordinated-omission-cumulative-wait-time.png alt="Cumulative Wait Time"></div></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content><div class=paragraph><p>The <strong>Average Call Duration experienced by customers was 1.9 minutes (1min 54s)</strong></p></div></td></tr></tbody></table></div></div><div class=paragraph><p>If you want to understand the math, please read <a href=#_appendix_a_detailed_math>Appendix A: Detailed Math</a></p></div></div><div class=sect2><h3 id=_why_are_the_numbers_so_different>Why are the numbers so different?</h3><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p>In our testing scenario, there were 10 testers who were blocked for 10 minutes. In reality users would <strong>keep calling the telephone line</strong> and being put on hold until an operator became available.</p></div><div class=paragraph><p><strong>Our test captured 10 Testers blocked for 10 minutes, but in reality 200 users would have been waiting for up to 10 minutes. We did not captured the waiting time of 200 of our users!</strong></p></div><div class=paragraph><p>Our flawed test showed the average order time of 36 seconds, but on average customers would have waited 1minute 54 seconds.</p></div><div class=paragraph><p><strong>The MISSED waiting time was not included in the summary statistics!</strong></p></div></td></tr></tbody></table></div></div></div><div class=sect2><h3 id=_second_attempt>Second Attempt</h3><div class="imageblock right text-center"><div class=content><img src=secondTest.png alt="Second Test" width=400 height=400></div></div><div class="olist arabic"><ol class=arabic><li><p>Each tester is given <strong>multiple phones</strong>, a list of orders to place <strong>and the time to start the call</strong> and a <strong>stopwatch</strong></p></li><li><p>The tester(s) calls the call center to place orders, <strong>at the time specified on their list</strong></p></li><li><p>If the first call does not complete before the next order needs to be placed, the tester users a <strong>different</strong> phone to make the next call. Any one tester can have multiple calls <strong>running concurrently</strong> at the same time.</p></li><li><p>After the call terminates, the tester checks the phone screen to see how the call took, and records this as the "Order Time"</p></li><li><p>After all the testers have run through their list of dummy orders. The call times for all the testers are collated and summary data is calculated.</p></li><li><p>If the tester runs out of phones, they start the stopwatch and stop the stopwatch again when one of their phones becomes available. After all of the orders have been placed, the stopwatch value is recorded the total <strong>blocked time</strong> for each tester during the load test. <strong>This is a direct measurement of Coordinated Omission.</strong></p></li></ol></div><div class="admonitionblock warning"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Warning</div></td><td class=content><div class=paragraph><p>This time the average call time was 1 minute 20 seconds, above our SLA.</p></div><div class=paragraph><p>We need to investigate why we are not meeting our SLA before rolling out <strong>BSTSI-callHandler-2.0</strong> to our customers</p></div></td></tr></tbody></table></div></div></div><div class=sect2><h3 id=_what_is_different>What is different?</h3><div class=paragraph><p>Why is this a more accurate reflection of reality. A small number of testers are trying to mimic 1000 customer orders. In reality, we wouldn’t have 10 customers, each placing 100 orders in sequence. We are more likely to receive 1000 different customers, each placing one order. They would not arrive in sequence, but in parallel and at random times.</p></div><div class=paragraph><p>In the first test, the testers could only make one call and made the calls in sequence. The maximum queue size was the number of testers. If there was a hiccup, they could not start a new call, but were blocked until they could end their current call. The wait time of any other customers trying to call the call center was missed.</p></div><div class=paragraph><p>In the second test, the testers could use multiple phones to place calls in parallel. By have a list of pre determined times, we define how many new customers calls were arriving at the call center. We can record the total call time for each virtual customer, and if we run out of phones (<strong>connections</strong>) to support the arrival rate, we record the blocked time.</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p>If there is <strong>any</strong> blocked time recorded, the <strong>results are invalid</strong>. It is invalid because we can no long queue any more customers, and record their wait time.</p></div></td></tr></tbody></table></div></div></div></div></div><div class=sect1><h2 id=_bringing_it_back_to_benchmark_design>Bringing it back to Benchmark Design</h2><div class=sectionbody></div></div><div class=sect1><h2 id=_what_can_be_done>What can be done?</h2><div class=sectionbody><div class=paragraph><p>A load generation tool that uses asynchronous I/O and uncouples threading from I/O, which measures timing independent on I/O is able to detect when the System Under Test is applying back-pressure to the load generator.</p></div><div class=paragraph><p>Tools such as <a href=https://hyperfoil.io/>Hyperfoil</a> will detect <strong>and report</strong> server back-pressure, so you <strong>can</strong> be sure that the load generator is reporting accurate response times without any Coordinated Omission effects from the SUT.</p></div></div></div><div class=sect1><h2 id=_how_i_tell_if_my_load_generation_tool_suffers_from_coordinated_omission>How I tell if my load generation tool suffers from Coordinated Omission?</h2><div class=sectionbody><div class=paragraph><p>Luckily there is a very simple test you can do! <code>CTRL+Z</code></p></div><div class=paragraph><p>While your benchmark is running, type <code>CTRL+Z</code> to Stop your process</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ ./run_my_service.sh
^Z
[1]+  Stopped                 ./run_my_service.sh</code></pre></div></div><div class=paragraph><p>After a period of time, start it again</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ fg 1
./run_my_service.sh</code></pre></div></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p>If the load generator <strong>only</strong> reports N number of requests, equivalent to the number of threads configured to generate load, taking the <code>Stopped</code> period of time and no more threads experiencing delay then you have a problem</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_see_it_in_action>See it in action</h2><div class=sectionbody><div class=paragraph><p>We covered a demonstration of Coordinated Omission in "Quarkus Insights #22: Performance Testing: Tips and Pitfalls"</p></div><div class="imageblock right text-center"><div class=content><iframe width=560 height=315 src="https://www.youtube.com/embed/xdG8b9iDYbE?start=1500" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div></div></div></div><div class=sect1><h2 id=_can_tune_away_this_problem>Can tune away this problem?</h2><div class=sectionbody><div class=sect2><h3 id=_what_happens_if_i_increase_the_number_of_threads>What happens if I increase the number of threads?</h3><div class=paragraph><p>Unfortunately not, you <strong>might</strong> be able to mitigate some of the issues through tuning, but you can <strong>never be certain that the results are accurate</strong>. The fundamental problem is that there is <strong>missing data</strong>, but you can not tell from the results if all the data has been captured.</p></div><div class=paragraph><p>Statements are often made such as <em>'As with any Load Testing tool, if you don’t correctly size the number of threads, you will face the "Coordinated Omission" problem which can give you wrong or inaccurate results.'</em> (<a href=https://jmeter.apache.org/usermanual/best-practices.html class=bare>https://jmeter.apache.org/usermanual/best-practices.html</a>)</p></div><div class=paragraph><p>The fundamental issue is not with the <em>size of the thread pool</em>, but whether the load generator threads that measure response time <em>can be blocked by the System Under Test</em>.</p></div></div><div class=sect2><h3 id=_cant_i_just_run_the_tests_for_longer>Can’t I just run the tests for longer?</h3><div class=paragraph><p>How many hiccups does your system have? How long do they last? Even if you can quantify those metrics, adjusting adding wait time to response times through a different data source is error prone. You might as well pick a load generation tool that handles coordinated omission and not have to normalize for a broken methodology.</p></div></div><div class=sect2><h3 id=_my_application_does_not_stop_that_long_surely_this_is_effect_negligible>My application does not stop that long, surely this is effect negligible?</h3><div class=paragraph><p>I have personally witnessed applications under load fully paused for 2-3 seconds to perform GC, every 5-10 seconds. Unless your load generator can measure that wait time, <strong>you will not know</strong> that the application was stalled. a load generator that suffers from co-rdinated omission has no way of measuring it</p></div></div><div class=sect2><h3 id=_cant_i_just_look_at_the_summary_stats_to_tell_if_my_run_was_affected>Can’t I just look at the summary stats to tell if my run was affected?</h3><div class=paragraph><p>It is very difficult! The maximum values will be the same. The mean and centile response times look sensible. The only way to tell is if the requests sent are equal to expected number of requests to be sent during the time period. However, if you can not set an arrival rate, it is not possible to determine if the expected number of requests were sent.</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>If the load generation tool does not decouple time measurement from generating load, the problem can not be tuned away.</strong></p></div></td></tr></tbody></table></div></div></div></div></div><div class=sect1><h2 id=_summary>Summary</h2><div class=sectionbody><div class=paragraph><p>Coordinated Omission is the unintended back pressure a system under test can apply to a load generation tool, that prevents that tool for accurately recording user experience.</p></div><div class=paragraph><p><strong>Response time</strong> = <strong>wait time</strong> + <strong>service time</strong>. A load generation tool that suffers from coordinated omission will only record <strong>service time</strong> and will fail to record <strong>wait time</strong>. Wait time <strong>can be significant</strong> and therefore can have a huge effect on summary statistics.</p></div><div class=paragraph><p>The worst part is, the load generator is unable to record the missed time, so users are completely unaware that there is a problem.</p></div><div class=paragraph><p>In order to design response time tests (typically associated with SLA’s) we need to use tools that accurately record response time, including wait time. More importantly, our tools should <strong>warn us if there is any unintended back-pressure from the System Under Test</strong>.</p></div><div class=paragraph><p>Choosing a tool such as <a href=https://hyperfoil.io/>Hyperfoil</a> will not only provide you with accurate measurements, it will also warn you and fail the benchmark if it detects hiccups that have effected the accuracy of the results.</p></div><hr></div></div><div class=sect1><h2 id=_further_reading>Further Reading</h2><div class=sectionbody><div class=paragraph><p>For more information, please visit the following articles;</p></div><div class=ulist><ul><li><p><a href=http://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html class=bare>http://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html</a></p></li></ul></div><hr></div></div><div class=sect1><h2 id=_appendix_a_detailed_math>Appendix A: Detailed Math</h2><div class=sectionbody><div class=sect2><h3 id=_in_our_test_scenario>In our test scenario</h3><div class=paragraph><p>we had <strong>10 testers</strong> placing orders each placing an order. At 6 mins there was an outage, that <strong>lasted 10 minutes</strong>.</p></div><div class=paragraph><p>Therefore, for 10 blocked orders;</p></div><div class=ulist><ul><li><p>there was a <strong>wait time of 10 minutes each</strong></p></li><li><p>there was a <strong>service time of 0.5 mins</strong></p></li><li><p>total <strong>order time was 10.5 minutes</strong></p></li></ul></div><div class=paragraph><p>For the remaining 990 orders;</p></div><div class=ulist><ul><li><p>there was a <strong>wait time of 0 minutes each</strong></p></li><li><p>there was a <strong>service time of 0.5 mins</strong></p></li><li><p>total <strong>order time was 0.5 minutes</strong></p></li></ul></div><div class="imageblock right text-center"><div class=content><img src=testAvOrderTime.png alt="Test Average Order time"></div></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content><div class=paragraph><p>The <strong>Average Call Duration measured during Testing was 0.6 minutes</strong></p></div></td></tr></tbody></table></div></div></div><div class=sect2><h3 id=_in_the_real_world>In the Real World</h3><div class=paragraph><p>Things are a bit more complicated;</p></div><div class=ulist><ul><li><p>new customers arrive at a rate of <strong>20 per minute</strong></p></li><li><p>therefore, during the first minute of outage, 20 customers will be placed in the switchboard queue and will have to wait for <strong>10 minutes</strong>, before the queue starts to empty</p></li><li><p>in the 2nd minute of the outage <strong>another 20 customer</strong> arrive, are placed in the switchboard queue and will have to wait for <strong>9 minutes</strong>, before the queue starts to empty</p></li><li><p>customers continue to arrive during the outage, filling up the switchboard queue</p></li><li><p><strong>once the outage is resolved</strong> the operators can start to process the queue of customers. But there is a maximum number of customers they can process in one minutes (60 customers per minute <strong>max throughput</strong>)</p></li><li><p>while the backlog is being processed at a rate of <strong>60 customers per minute</strong>, <strong>20 customers per minute</strong> are still being added to the back of the queue.</p></li></ul></div><div class=paragraph><p>During the outage, the total <strong>Wait time</strong> can be modelled by;</p></div><div class="imageblock right text-center"><div class=content><img src=equation-arrival-wait.png alt="Real blocked time wait"></div></div><div class=paragraph><p>After the outage, while the backlog is cleared, the total <strong>Wait time</strong> can be modelled by;</p></div><div class="imageblock right text-center"><div class=content><img src=equation-backlog-wait.png alt="Real blocked time wait"></div></div><div class=paragraph><p>If we calculate our scenario;</p></div><div class="imageblock right text-center"><div class=content><img src=realAvWaitTime.png alt="Real Average Order time"></div></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content><div class=paragraph><p>The <strong>Average call duration <em>experienced</em> by customers was 1.9 minutes!</strong></p></div></td></tr></tbody></table></div></div></div></div></div></section><footer class=article-footer></footer></article><footer class=site-footer><section class=copyright>&copy;
2022 Red Hat App Services Performance Team</section><section class=powerby></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>