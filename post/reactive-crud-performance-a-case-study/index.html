<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=" By carefully fixing and designing a performance test to ensure that only Quarkus is being stressed, throughput improves from 1.75 req/sec to nearly 26,000 req/sec
"><title>Reactive CRUD Performance: A Case Study</title><link rel=canonical href=http://example.org/post/reactive-crud-performance-a-case-study/><link rel=stylesheet href=/scss/style.min.c3ce6bc8f68d8b32c7079ef6cf45fdf24e00003418a0955c1897115bd2ea7f1c.css><meta property="og:title" content="Reactive CRUD Performance: A Case Study"><meta property="og:description" content=" By carefully fixing and designing a performance test to ensure that only Quarkus is being stressed, throughput improves from 1.75 req/sec to nearly 26,000 req/sec
"><meta property="og:url" content="http://example.org/post/reactive-crud-performance-a-case-study/"><meta property="og:site_name" content="Red Hat App Services Performance Team"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2022-11-17T00:00:00+00:00"><meta property="article:modified_time" content="2022-11-17T00:00:00+00:00"><meta property="og:image" content="http://example.org/post/reactive-crud-performance-a-case-study/apples-to-oranges.png"><meta name=twitter:title content="Reactive CRUD Performance: A Case Study"><meta name=twitter:description content=" By carefully fixing and designing a performance test to ensure that only Quarkus is being stressed, throughput improves from 1.75 req/sec to nearly 26,000 req/sec
"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://example.org/post/reactive-crud-performance-a-case-study/apples-to-oranges.png"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.setItem(e,"light")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/redHatLogo_hu1c053dbd2674ef6a4ce5cecbb630113c_5104_300x0_resize_q75_box.jpeg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Red Hat App Services Performance Team</a></h1><h2 class=site-description></h2></div></header><ol class=social-menu><li><a href=https://github.com/RedHatPerf/ target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/page/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/page/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/page/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><div class=menu-bottom-section></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/post/reactive-crud-performance-a-case-study/><img src=/post/reactive-crud-performance-a-case-study/apples-to-oranges_hu075406026e3cde1b9d53201b6232df5f_414123_800x0_resize_box_3.png srcset="/post/reactive-crud-performance-a-case-study/apples-to-oranges_hu075406026e3cde1b9d53201b6232df5f_414123_800x0_resize_box_3.png 800w, /post/reactive-crud-performance-a-case-study/apples-to-oranges_hu075406026e3cde1b9d53201b6232df5f_414123_1600x0_resize_box_3.png 1600w" width=800 height=441 loading=lazy alt="Featured image of post Reactive CRUD Performance: A Case Study"></a></div><div class=article-details><header class=article-category><a href=/categories/performance/>performance</a>
<a href=/categories/methodology/>methodology</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/post/reactive-crud-performance-a-case-study/>Reactive CRUD Performance: A Case Study</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Nov 17, 2022</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>13 minute read</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><a href=http://example.org/authors/john-ohara/>John O'Hara</a></div></footer></div></header><section class=article-content><div class=paragraph><p>We were recently approached for comment about the relative performance of Quarkus for a reactive CRUD workload. This is a good case study into performance test design and some of the considerations required and hurdles that need to be overcome. What methodology can we derive for ensuring that the test we are performing is indeed the test that we are expecting?</p></div><div class=sect1><h2 id=_why_is_quarkus_600x_times_slower_than_insert_framework_here>"Why is Quarkus 600x times slower than <code>{INSERT_FRAMEWORK_HERE}</code>?!?"</h2><div class=sectionbody><div class=paragraph><p>A recent report of bad result from Quarkus warranted some further investigation. On the face of it the results looked bad, really bad, for Quarkus.</p></div><div class=sect2><h3 id=_tldr>tl;dr</h3><div class=paragraph><p>By correcting implementation errors in a benchmark test, and carefully designing the test environment to ensure that only the application is being stressed, Quarkus goes from handling <strong>1.75 req/sec</strong> to nearly <strong>26,000 req/sec</strong>. Each request queried and wrote to a mysql database, using the same load driver and hardware.</p></div></div></div></div><div class=sect1><h2 id=_test_architecture>Test architecture</h2><div class=sectionbody><div class=paragraph><p>The test that was shared with us is a simple load test that updates a database via REST invocations;</p></div><div class=imageblock><div class=content><img src=reactiveBenchmark.png alt=reactiveBenchmark></div></div><div class="olist arabic"><ol class=arabic><li><p>A load generator creates a continuous stream of HTTP POST requests to a REST api. In this case <a href=https://github.com/wg/wrk>wrk</a></p></li><li><p>A Quarkus application process the request via <a href=https://quarkus.io/guides/resteasy-reactive>RESTEasy Reactive</a></p></li><li><p>The Quarkus application queries and updates a MySQL database instance via <a href=https://hibernate.org/reactive/>Hibernate Reactive</a></p></li></ol></div><div class=paragraph><p>The source code for the test can be found here: <a href=https://github.com/thiagohora/tutorials/tree/fix_jmeter_test class=bare>https://github.com/thiagohora/tutorials/tree/fix_jmeter_test</a></p></div><div class=paragraph><p>To learn more about creating Reactive Applications with Quarkus, please read the <a href=https://quarkus.io/guides/getting-started-reactive>Getting Started With Reactive</a> guide</p></div></div></div><div class=sect1><h2 id=_initial_results>Initial Results <span class=image><img src=emoji-unhappy.png alt=Unhappy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>Initial results for Quarkus were not promising;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.26s    10.29s   30.03s    77.78%
    Req/Sec    72.55     97.66   270.00     81.82%
  105 requests in 1.00m, 20.69KB read
  Socket errors: connect 0, read 10, write 0, timeout 0
  Non-2xx or 3xx responses: 10
Requests/sec:      1.75
Transfer/sec:     352.77B</code></pre></div></div><div class=paragraph><p>That was 105 requests in 60 seconds, with 10 errors. Only 95 requests had been successfully sent in 60 seconds, or <strong>1.75 req/sec</strong></p></div><div class=paragraph><p>Running the comparison test on my machine;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    35.78ms   43.69ms 568.52ms   92.67%
    Req/Sec   171.93    113.83   777.00     80.61%
  20228 requests in 1.00m, 3.70MB read
Requests/sec:    336.86
Transfer/sec:     63.04KB</code></pre></div></div><div class=paragraph><p>Overall, the request rate that Quarkus could support was only <strong>1.75 req/sec!!</strong> Ok, so it wasn’t <strong>600</strong> times slower, but it was <strong>192</strong> times slower on my machine.</p></div><div class=paragraph><p>but…​ something was not correct, Quarkus was displaying the following exception in the service logs;</p></div><div class=listingblock><div class=content><pre class=highlight><code>2022-06-17 15:20:44,507 ERROR [org.hib.rea.errors] (vert.x-eventloop-thread-45) HR000057: Failed to execute statement [select zipcode0_.zip as zip1_0_0_, zipcode0_.city as city2_0_0_, zipcode0_.county as county3_0_0_, zipcode0_.state as state4_0_0_, zipcode0_.timezone as timezone5_0_0_, zipcode0_.type as type6_0_0_ from ZipCode zipcode0_ where zipcode0_.zip=?]: could not load an entity: [com.baeldung.quarkus_project.ZipCode#08231]: java.util.concurrent.CompletionException: io.vertx.core.impl.NoStackTraceThrowable: Timeout
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at io.vertx.core.Future.lambda$toCompletionStage$2(Future.java:362)
	...
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: io.vertx.core.impl.NoStackTraceThrowable: Timeout</code></pre></div></div><div class=paragraph><p>An initial investigation showed that the number of open mysql connections during the test was very high: <strong>96 open connections</strong></p></div><div class=listingblock><div class=content><pre class=highlight><code>mysql&gt; show status like &#39;%onn%&#39;;
+-----------------------------------------------+---------------------+
| Variable_name                                 | Value               |
+-----------------------------------------------+---------------------+
...
| Max_used_connections                          | 96                  |
| Max_used_connections_time                     | 2022-06-17 14:20:07 |
...
| Threads_connected                             | 96                  |
+-----------------------------------------------+---------------------+
16 rows in set (0.01 sec)</code></pre></div></div><div class=paragraph><p>And checking the number of inserts the application had managed to perform within 1minutes;</p></div><div class=listingblock><div class=content><pre class=highlight><code>mysql&gt; select count(*) from ZipCode;
+----------+
| count(*) |
+----------+
|       95 |
+----------+
1 row in set (0.00 sec)</code></pre></div></div><div class=paragraph><p>There was obviously something wrong with the database connections! Each connection was committing only a single value to the database and no more progress was being made. The number of entries in the database tallied <em>exactly</em> with the number of successful HTTP requests.</p></div><div class=paragraph><p>Reviewing the CPU time for the Quarkus process confirmed that no further work was being done after the initial 95 commits to the database, the application was deadlocked;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ pidstat -p 869871 1
Linux 5.17.11-200.fc35.x86_64 (localhost.localdomain) 	17/06/22 	_x86_64_	(32 CPU)

15:32:41      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
15:32:42     1000    869871    0.00    0.00    0.00    0.00    0.00    22  java
15:32:43     1000    869871    0.00    0.00    0.00    0.00    0.00    22  java
15:32:44     1000    869871    0.00    0.00    0.00    0.00    0.00    22  java
15:32:45     1000    869871    0.00    0.00    0.00    0.00    0.00    22  java
15:32:46     1000    869871    0.00    0.00    0.00    0.00    0.00    22  java</code></pre></div></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>Is the application behaving as expected?</strong></p></div><div class=paragraph><p>If the application is erroring, the results are not valid. Before continuing, investigate <strong>why</strong> the errors are occurring and fix the application.</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_initial_inspection_of_code>Initial inspection of code</h2><div class=sectionbody><div class=paragraph><p>A quick review of the code revealed the deadlocking issue;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-java data-lang=java>@POST
@Transactional
public Uni&lt;ZipCode&gt; create(ZipCode zipCode) {
    return getById(zipCode.getZip())
        .onItem()
        .ifNull()
        .switchTo(createZipCode(zipCode))
        .onFailure(PersistenceException.class)
        .recoverWithUni(() -&gt; getById(zipCode.getZip()));
}</code></pre></div></div><div class=paragraph><p>Ah Ha! the endpoint is annotated with <code>@Transactional</code>. The application is using Hibernate Reactive, so instead we need to use the <code>@ReactiveTransactional</code> annotation. For further details, please read the <a href=https://quarkus.io/guides/hibernate-reactive-panache#transactions>Simplified Hibernate Reactive with Panache</a> guide. This can be confusing, but conversations have started about how to clarify the difference requirements, warning users if there is an issue.</p></div></div></div><div class=sect1><h2 id=_quarkus_application_fixed>Quarkus Application Fixed <span class=image><img src=emoji-happy.png alt=Happy width=35 height=35></span></h2><div class=sectionbody><div class=listingblock><div class=content><pre class=highlight><code class=language-java data-lang=java>@POST
@ReactiveTransactional
public Uni&lt;ZipCode&gt; create(ZipCode zipCode) {
    return getById(zipCode.getZip())
        .onItem()
        .ifNull()
        .switchTo(createZipCode(zipCode))
        .onFailure(PersistenceException.class)
        .recoverWithUni(() -&gt; getById(zipCode.getZip()));
}</code></pre></div></div><div class=paragraph><p>Let’s try again:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    30.06ms   33.67ms 351.38ms   87.66%
    Req/Sec   197.60    145.88     1.14k    82.24%
  23427 requests in 1.00m, 4.60MB read
  Socket errors: connect 0, read 3, write 0, timeout 0
  Non-2xx or 3xx responses: 3
Requests/sec:    390.21
Transfer/sec:     78.40KB</code></pre></div></div><div class=paragraph><p><strong>390.21 req/sec!!</strong> that’s much better!!</p></div><div class=paragraph><p>With the test fixed, we can see a lot more data in the database table;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>mysql&gt; select count(*) from ZipCode;
+----------+
| count(*) |
+----------+
|    10362 |
+----------+
1 row in set (0.00 sec)</code></pre></div></div><div class="admonitionblock note"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Note</div></td><td class=content>The test has been designed to query the database if a ZipCode already exists, before attempting to insert a new ZipCode. There are a finite number of ZipCodes, so as the test progresses, the number of ZipCode entries will tend towards the maximum number of ZipCodes. The workload progresses from being write heavy to read heavy.</td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_same_results>Same results <span class=image><img src=emoji-unhappy.png alt=Unhappy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>but…​ my the hard disk on my machine was making a <strong>lot</strong> of noise during the test! The Quarkus result of <strong>390.21 req/sec</strong> is suspiciously similar to the comparison baseline of <strong>336.86 req/sec</strong>, and…​</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ pidstat -p 873146 1
...
15:46:29      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
15:46:30     1000    873146   59.00    6.00    0.00    0.00   65.00    12  java
15:46:31     1000    873146   57.00    4.00    0.00    0.00   61.00    12  java
15:46:32     1000    873146   50.00    3.00    0.00    0.00   53.00    12  java
15:46:33     1000    873146   27.00    5.00    0.00    0.00   32.00    12  java
15:46:34     1000    873146   32.00    3.00    0.00    0.00   35.00    12  java
15:46:35     1000    873146   50.00    4.00    0.00    0.00   54.00    12  java
15:46:36     1000    873146   27.00    3.00    0.00    0.00   30.00    12  java
15:46:37     1000    873146   27.00    4.00    0.00    0.00   31.00    12  java
15:46:38     1000    873146   39.00    4.00    0.00    0.00   43.00    12  java
15:46:39     1000    873146   48.00    2.00    0.00    0.00   50.00    12  java
15:46:40     1000    873146   40.00    2.00    0.00    0.00   42.00    12  java
15:46:41     1000    873146   28.00    5.00    0.00    0.00   33.00    12  java
15:46:42     1000    873146   23.00    4.00    0.00    0.00   27.00    12  java</code></pre></div></div><div class=paragraph><p>The application is using less than <strong>0.5</strong> cores on a <strong>32</strong> core machine…​ hmm!</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>Is the application the bottleneck?</strong></p></div><div class=paragraph><p>If a <strong>system component</strong> is the performance bottleneck (i.e. not the application under test), we are not actually stress testing the application.</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_move_to_a_faster_disk>Move to a faster Disk <span class=image><img src=emoji-happy.png alt=Happy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>Let’s move the database files to a faster disk;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ docker run -d --rm --name mysqldb --network=host -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=baeldung -v /home/user/mysqlData:/var/lib/mysql  -d mysql:5.7.38 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</code></pre></div></div><div class=paragraph><p>and re-run the test</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.97ms   17.85ms 319.79ms   98.44%
    Req/Sec    12.99k     6.45k   18.88k    77.23%
  1538167 requests in 1.00m, 301.75MB read
  Socket errors: connect 0, read 4, write 0, timeout 0
  Non-2xx or 3xx responses: 4
Requests/sec:  25599.85
Transfer/sec:      5.02MB</code></pre></div></div><div class=paragraph><p>Sit back, Relax and Profit! <strong>25,599.85 req/sec!</strong></p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>Do not stop here!</strong></p></div><div class=paragraph><p>While it is easy to claim we have resolved the issue, for comparisons, we still do not have a controlled environment to run tests!</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_system_bottleneck_still_exists>System bottleneck still exists <span class=image><img src=emoji-unhappy.png alt=Unhappy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>the Quarkus process is now using 4.5 cores…​</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>]$ pidstat -p 884208 1
Linux 5.17.11-200.fc35.x86_64 (localhost.localdomain) 	17/06/22 	_x86_64_	(32 CPU)

16:12:50      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
16:12:51     1000    884208  294.00  175.00    0.00    0.00  469.00    26  java
16:12:52     1000    884208  305.00  173.00    0.00    0.00  478.00    26  java
16:12:53     1000    884208  304.00  173.00    0.00    0.00  477.00    26  java
16:12:54     1000    884208  299.00  169.00    0.00    0.00  468.00    26  java
16:12:55     1000    884208  296.00  173.00    0.00    0.00  469.00    26  java
16:12:56     1000    884208  298.00  171.00    0.00    0.00  469.00    26  java
16:12:57     1000    884208  308.00  175.00    0.00    0.00  483.00    26  java
16:12:58     1000    884208  301.00  177.00    0.00    0.00  478.00    26  java
16:12:59     1000    884208  305.00  166.00    0.00    0.00  471.00    26  java
16:13:00     1000    884208  304.00  169.00    0.00    0.00  473.00    26  java
16:13:01     1000    884208  307.00  172.00    0.00    0.00  479.00    26  java
16:13:02     1000    884208  301.00  174.00    0.00    0.00  475.00    26  java</code></pre></div></div><div class=paragraph><p>but…​ the system is <strong>60%</strong> idle</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b swpd    free    buff   cache     si   so    bi    bo    in     cs us sy id wa st
14  0 5254976 9665088 590824 4895220    0    0     0     0 50997 715648 25 16 59  0  0
16  0 5254976 9667204 590824 4895220    0    0     0  1372 50995 710429 24 16 60  0  0
15  0 5254976 9666244 590824 4895232    0    0     0     0 51544 707477 24 16 59  0  0
11  0 5254976 9664892 590872 4895160    0    0     0   980 51178 700680 24 16 60  0  0
14  0 5254976 9662968 590880 4895232    0    0     0    12 54800 710039 25 16 59  0  0</code></pre></div></div><div class=paragraph><p>We still have a bottleneck outside of the application, most likely within mysql or we are still I/O bound!</p></div><div class=paragraph><p>At this point, we have a couple of options, we can either;</p></div><div class=literalblock><div class=content><pre>A) tune MySQL/IO so that they are no longer the bottleneck</pre></div></div><div class=paragraph><p>or</p></div><div class=literalblock><div class=content><pre>B) constrain that application below the maximum, such that the rest of the system is operating within it&#39;s limits</pre></div></div><div class=paragraph><p>The easiest option is to simply constrain the application.</p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>Choose your scaling methodology</strong></p></div><div class=paragraph><p>We can either scale up or tune the system, or we can scale down the application to below the limits of the system.</p></div><div class=paragraph><p>Choosing to scale up the system, or constrain the application, is a decision dependent on the goals of the testing.</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_constrain_application>Constrain application <span class=image><img src=emoji-happy.png alt=Happy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>We will remove the MySQL/System bottleneck by constraining the application to 4 cpu cores, therefore reducing the maximum load the application can drive to the database. We achieve this by running the application in docker;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ docker build -f ./src/main/docker/Dockerfile.jvm -t quarkus-project:0.1-SNAPSHOT .
...
Successfully built 0cd0d50404ac
Successfully tagged quarkus-project:0.1-SNAPSHOT

$ docker run --network host --cpuset-cpus=0-3 quarkus-project:0.1-SNAPSHOT</code></pre></div></div><div class=paragraph><p>and re-running the test;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     5.36ms   44.30ms 766.89ms   98.94%
    Req/Sec     9.50k     4.45k   15.37k    78.52%
  1121692 requests in 1.00m, 220.06MB read
  Socket errors: connect 0, read 1, write 0, timeout 0
  Non-2xx or 3xx responses: 1
Requests/sec:  18667.87
Transfer/sec:      3.66MB</code></pre></div></div><div class=paragraph><p>Ok, so we are not at Max Throughput, but we <strong>have</strong> removed the system outside of the application as a bottleneck. <strong>The bottleneck is NOW the application</strong></p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>Create an environment where the comparisons are valid</strong></p></div><div class=paragraph><p>By constraining the application, we are not running at absolute Max Throughput possible, <em>but</em> we have created an environment that allows for comparisons between frameworks.</p></div><div class=paragraph><p>With a constrained application environment, we will not be in the situation where one or more frameworks are sustaining throughput levels that are at the limit of the system.</p></div><div class=paragraph><p>If any application <em>is</em> at the system limit, the results are invalid.</p></div></td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_all_network_traffic_is_not_equal>All network traffic is not equal! <span class=image><img src=emoji-unhappy.png alt=Unhappy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>Further investigation showed that Quarkus is not running with TLS enabled between the application and database, so database network traffic is running un-encrypted. Let’s fix that;</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-properties data-lang=properties>quarkus.datasource.reactive.url=${DB_URL:mysql://localhost:3306/baeldung?useSSL=false&amp;tlsVersion=TLSv1.2}
quarkus.datasource.reactive.max-size=95
quarkus.datasource.reactive.mysql.ssl-mode=required
#&#34;don&#39;t do this in prod, don&#39;t do this @ home, don&#39;t do this !&#34;
#required for this test as mysql cert is self-signed
quarkus.datasource.reactive.trust-all=true</code></pre></div></div><div class=paragraph><p>and re-run</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H &#39;Host: localhost&#39; http://localhost:8080
Running 1m test @ http://localhost:8080
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.44ms   12.94ms 354.67ms   98.17%
    Req/Sec     7.55k     3.55k   11.94k    77.93%
  898541 requests in 1.00m, 176.26MB read
  Socket errors: connect 0, read 2, write 0, timeout 0
  Non-2xx or 3xx responses: 2
Requests/sec:  14955.61
Transfer/sec:      2.93MB</code></pre></div></div><div class=paragraph><p>This provided us with a final, comparable throughput result of <strong>14,955.61 req/sec</strong></p></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content><div class=paragraph><p><strong>For comparisons, we need to ensure that each framework is performing the same work</strong></p></div></td></tr></tbody></table></div></div><div class=imageblock><div class=content><img src=apples-to-oranges.png alt="apples to oranges"></div></div></div></div><div class=sect1><h2 id=_results>Results <span class=image><img src=emoji-happy.png alt=Happy width=35 height=35></span></h2><div class=sectionbody><div class=paragraph><p>Is Quarkus really 600x times slower than Framework X/Y/Z? <strong>Of course not!</strong></p></div><div class=paragraph><p>On my machine;</p></div><div class="olist arabic"><ol class=arabic><li><p>the initial result was <strong>1.75 req/sec</strong>.</p></li><li><p>fixing the application brought that up to <strong>390.21 req/sec</strong></p></li><li><p>fixing some of the system bottlenecks gave us <strong>25,599.85 req/sec</strong></p></li><li><p>constraining the application, so that a fairer comparison with other frameworks can be made resulted in <strong>18,667.87 req/sec</strong></p></li><li><p>and finally, enabling TLS encryption to the database gives a final result of <strong>14,955.61 req/sec</strong></p></li></ol></div><div class=imageblock><div class=content><img src=results.png alt=results></div></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content>Run <strong>5</strong> gives us our baseline for comparison, <strong>14,955.61 req//sec</strong></td></tr></tbody></table></div></div><div class=sect2><h3 id=_where_does_that_leave_quarkus_compared_to_framework_xyz>Where does that leave Quarkus compared to Framework X/Y/Z?</h3><div class=paragraph><p>well…​ that is an exercise for the reader ;-)</p></div></div></div></div><div class=sect1><h2 id=_summary>Summary</h2><div class=sectionbody><div class=paragraph><p>Does these results show that Quarkus is quick? Well kinda, they hint at it, but there are still issues with the methodology that need resolving.</p></div><div class=paragraph><p>However, when faced with a benchmark result, especially one that does not appear to make sense, there are a number of steps you can take to validate the result;</p></div><div class=ulist><ul><li><p><strong>Fix the application</strong>: Are there errors? Is the test functioning as expected? If there are errors, resolve them</p></li><li><p><strong>Ensure the application is the bottleneck</strong>: What are the limiting factors for the test? Is the test CPU, Network I/O, Disk I/O bound?</p></li><li><p><strong>Do not stop evaluating the test when you see a <em>"good"</em> result</strong>. For comparisons, you need to ensure that <em>every</em> framework is the limiting factor for performance and not the system.</p></li><li><p><strong>Chose how to constrain the application</strong>: either by scaling up the system, or scaling down the application.</p></li><li><p><strong>Validate that all frameworks are doing the same work</strong>. For comparisons, are the frameworks performing the same work?</p></li><li><p><strong>Ensure al frameworks are providing the same level of security</strong>. Are the semantics the same? e.g. same TLS encoding? same db transaction isolation levels?</p></li></ul></div><div class="admonitionblock important"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Important</div></td><td class=content>The System Under Test includes the <strong>System</strong>. Do not automatically <em>assume</em> that your application is the bottleneck</td></tr></tbody></table></div></div></div></div><div class=sect1><h2 id=_notes_on_methodology>Notes on Methodology</h2><div class=sectionbody><div class="admonitionblock caution"><div class=table-wrapper><table><tbody><tr><td class=icon><div class=title>Caution</div></td><td class=content><div class=paragraph><p><strong>Does this benchmark tell us everything we need to know about how Quarkus behaves under load? Not really! It gives us <em>one</em> data point</strong></p></div><div class=paragraph><p>In order to have a meaningful understanding of behavior under load, the following issues with methodology needs to be addressed;</p></div><div class=ulist><ul><li><p>Load generation, database and application are all running on a single machine. The current test does not stress any of the network stack and there are side effects due to co-location of services. The application topology needs to be representative of a production environment.</p></li><li><p>This test does not measure application responsiveness from a <em>users perspective</em>. A tool that does not suffer from <a href=http://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html>coordinated omissions</a>, such as <a href=https://hyperfoil.io/>Hyperfoil</a>, is required to accurately measure service response time, including system wait time. <strong>throughput != response time</strong> and response time is what matters to users!</p></li><li><p>The mixture of read/writes to the database changes throughout the duration of the test. Initially the load is very write heavy, as time progresses, the database load is predominantly read heavy. A more consistent pattern of read/writes should be maintained throughout the test duration.</p></li><li><p>The applications are not given time to correctly "warm up", therefore the results are a mixture of Java code running in interpreted mode and compiled mode.</p></li><li><p>Due to the issue above, it is not possible to derive how a framework would behave with real-world production traffic from this test</p></li><li><p>As with any benchmarking, it is always best to <strong>test a simulation of your production traffic</strong></p></li></ul></div></td></tr></tbody></table></div></div></div></div></section><footer class=article-footer></footer></article><footer class=site-footer><section class=copyright>&copy;
2022 Red Hat App Services Performance Team</section><section class=powerby></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>