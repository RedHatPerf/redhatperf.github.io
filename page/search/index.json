[{"content":" We were recently approached for comment about the relative performance of Quarkus for a reactive CRUD workload. This is a good case study into performance test design and some of the considerations required and hurdles that need to be overcome. What methodology can we derive for ensuring that the test we are performing is indeed the test that we are expecting?\n\u0026#34;Why is Quarkus 600x times slower than {INSERT_FRAMEWORK_HERE}?!?\u0026#34; A recent report of bad result from Quarkus warranted some further investigation. On the face of it the results looked bad, really bad, for Quarkus.\ntl;dr By correcting implementation errors in a benchmark test, and carefully designing the test environment to ensure that only the application is being stressed, Quarkus goes from handling 1.75 req/sec to nearly 26,000 req/sec. Each request queried and wrote to a mysql database, using the same load driver and hardware.\nTest architecture The test that was shared with us is a simple load test that updates a database via REST invocations;\nA load generator creates a continuous stream of HTTP POST requests to a REST api. In this case wrk\nA Quarkus application process the request via RESTEasy Reactive\nThe Quarkus application queries and updates a MySQL database instance via Hibernate Reactive\nThe source code for the test can be found here: https://github.com/thiagohora/tutorials/tree/fix_jmeter_test\nTo learn more about creating Reactive Applications with Quarkus, please read the Getting Started With Reactive guide\nInitial Results Initial results for Quarkus were not promising;\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 6.26s 10.29s 30.03s 77.78% Req/Sec 72.55 97.66 270.00 81.82% 105 requests in 1.00m, 20.69KB read Socket errors: connect 0, read 10, write 0, timeout 0 Non-2xx or 3xx responses: 10 Requests/sec: 1.75 Transfer/sec: 352.77B That was 105 requests in 60 seconds, with 10 errors. Only 95 requests had been successfully sent in 60 seconds, or 1.75 req/sec\nRunning the comparison test on my machine;\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 35.78ms 43.69ms 568.52ms 92.67% Req/Sec 171.93 113.83 777.00 80.61% 20228 requests in 1.00m, 3.70MB read Requests/sec: 336.86 Transfer/sec: 63.04KB Overall, the request rate that Quarkus could support was only 1.75 req/sec!! Ok, so it wasn’t 600 times slower, but it was 192 times slower on my machine.\nbut…​ something was not correct, Quarkus was displaying the following exception in the service logs;\n2022-06-17 15:20:44,507 ERROR [org.hib.rea.errors] (vert.x-eventloop-thread-45) HR000057: Failed to execute statement [select zipcode0_.zip as zip1_0_0_, zipcode0_.city as city2_0_0_, zipcode0_.county as county3_0_0_, zipcode0_.state as state4_0_0_, zipcode0_.timezone as timezone5_0_0_, zipcode0_.type as type6_0_0_ from ZipCode zipcode0_ where zipcode0_.zip=?]: could not load an entity: [com.baeldung.quarkus_project.ZipCode#08231]: java.util.concurrent.CompletionException: io.vertx.core.impl.NoStackTraceThrowable: Timeout at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:636) at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162) at io.vertx.core.Future.lambda$toCompletionStage$2(Future.java:362) ... at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:833) Caused by: io.vertx.core.impl.NoStackTraceThrowable: Timeout An initial investigation showed that the number of open mysql connections during the test was very high: 96 open connections\nmysql\u0026gt; show status like \u0026#39;%onn%\u0026#39;; +-----------------------------------------------+---------------------+ | Variable_name | Value | +-----------------------------------------------+---------------------+ ... | Max_used_connections | 96 | | Max_used_connections_time | 2022-06-17 14:20:07 | ... | Threads_connected | 96 | +-----------------------------------------------+---------------------+ 16 rows in set (0.01 sec) And checking the number of inserts the application had managed to perform within 1minutes;\nmysql\u0026gt; select count(*) from ZipCode; +----------+ | count(*) | +----------+ | 95 | +----------+ 1 row in set (0.00 sec) There was obviously something wrong with the database connections! Each connection was committing only a single value to the database and no more progress was being made. The number of entries in the database tallied exactly with the number of successful HTTP requests.\nReviewing the CPU time for the Quarkus process confirmed that no further work was being done after the initial 95 commits to the database, the application was deadlocked;\n$ pidstat -p 869871 1 Linux 5.17.11-200.fc35.x86_64 (localhost.localdomain) 17/06/22 _x86_64_\t(32 CPU) 15:32:41 UID PID %usr %system %guest %wait %CPU CPU Command 15:32:42 1000 869871 0.00 0.00 0.00 0.00 0.00 22 java 15:32:43 1000 869871 0.00 0.00 0.00 0.00 0.00 22 java 15:32:44 1000 869871 0.00 0.00 0.00 0.00 0.00 22 java 15:32:45 1000 869871 0.00 0.00 0.00 0.00 0.00 22 java 15:32:46 1000 869871 0.00 0.00 0.00 0.00 0.00 22 java Important Is the application behaving as expected?\nIf the application is erroring, the results are not valid. Before continuing, investigate why the errors are occurring and fix the application.\nInitial inspection of code A quick review of the code revealed the deadlocking issue;\n@POST @Transactional public Uni\u0026lt;ZipCode\u0026gt; create(ZipCode zipCode) { return getById(zipCode.getZip()) .onItem() .ifNull() .switchTo(createZipCode(zipCode)) .onFailure(PersistenceException.class) .recoverWithUni(() -\u0026gt; getById(zipCode.getZip())); } Ah Ha! the endpoint is annotated with @Transactional. The application is using Hibernate Reactive, so instead we need to use the @ReactiveTransactional annotation. For further details, please read the Simplified Hibernate Reactive with Panache guide. This can be confusing, but conversations have started about how to clarify the difference requirements, warning users if there is an issue.\nQuarkus Application Fixed @POST @ReactiveTransactional public Uni\u0026lt;ZipCode\u0026gt; create(ZipCode zipCode) { return getById(zipCode.getZip()) .onItem() .ifNull() .switchTo(createZipCode(zipCode)) .onFailure(PersistenceException.class) .recoverWithUni(() -\u0026gt; getById(zipCode.getZip())); } Let’s try again:\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 30.06ms 33.67ms 351.38ms 87.66% Req/Sec 197.60 145.88 1.14k 82.24% 23427 requests in 1.00m, 4.60MB read Socket errors: connect 0, read 3, write 0, timeout 0 Non-2xx or 3xx responses: 3 Requests/sec: 390.21 Transfer/sec: 78.40KB 390.21 req/sec!! that’s much better!!\nWith the test fixed, we can see a lot more data in the database table;\nmysql\u0026gt; select count(*) from ZipCode; +----------+ | count(*) | +----------+ | 10362 | +----------+ 1 row in set (0.00 sec) Note The test has been designed to query the database if a ZipCode already exists, before attempting to insert a new ZipCode. There are a finite number of ZipCodes, so as the test progresses, the number of ZipCode entries will tend towards the maximum number of ZipCodes. The workload progresses from being write heavy to read heavy. Same results but…​ my the hard disk on my machine was making a lot of noise during the test! The Quarkus result of 390.21 req/sec is suspiciously similar to the comparison baseline of 336.86 req/sec, and…​\n$ pidstat -p 873146 1 ... 15:46:29 UID PID %usr %system %guest %wait %CPU CPU Command 15:46:30 1000 873146 59.00 6.00 0.00 0.00 65.00 12 java 15:46:31 1000 873146 57.00 4.00 0.00 0.00 61.00 12 java 15:46:32 1000 873146 50.00 3.00 0.00 0.00 53.00 12 java 15:46:33 1000 873146 27.00 5.00 0.00 0.00 32.00 12 java 15:46:34 1000 873146 32.00 3.00 0.00 0.00 35.00 12 java 15:46:35 1000 873146 50.00 4.00 0.00 0.00 54.00 12 java 15:46:36 1000 873146 27.00 3.00 0.00 0.00 30.00 12 java 15:46:37 1000 873146 27.00 4.00 0.00 0.00 31.00 12 java 15:46:38 1000 873146 39.00 4.00 0.00 0.00 43.00 12 java 15:46:39 1000 873146 48.00 2.00 0.00 0.00 50.00 12 java 15:46:40 1000 873146 40.00 2.00 0.00 0.00 42.00 12 java 15:46:41 1000 873146 28.00 5.00 0.00 0.00 33.00 12 java 15:46:42 1000 873146 23.00 4.00 0.00 0.00 27.00 12 java The application is using less than 0.5 cores on a 32 core machine…​ hmm!\nImportant Is the application the bottleneck?\nIf a system component is the performance bottleneck (i.e. not the application under test), we are not actually stress testing the application.\nMove to a faster Disk Let’s move the database files to a faster disk;\n$ docker run -d --rm --name mysqldb --network=host -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=baeldung -v /home/user/mysqlData:/var/lib/mysql -d mysql:5.7.38 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci and re-run the test\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 2.97ms 17.85ms 319.79ms 98.44% Req/Sec 12.99k 6.45k 18.88k 77.23% 1538167 requests in 1.00m, 301.75MB read Socket errors: connect 0, read 4, write 0, timeout 0 Non-2xx or 3xx responses: 4 Requests/sec: 25599.85 Transfer/sec: 5.02MB Sit back, Relax and Profit! 25,599.85 req/sec!\nImportant Do not stop here!\nWhile it is easy to claim we have resolved the issue, for comparisons, we still do not have a controlled environment to run tests!\nSystem bottleneck still exists the Quarkus process is now using 4.5 cores…​\n]$ pidstat -p 884208 1 Linux 5.17.11-200.fc35.x86_64 (localhost.localdomain) 17/06/22 _x86_64_\t(32 CPU) 16:12:50 UID PID %usr %system %guest %wait %CPU CPU Command 16:12:51 1000 884208 294.00 175.00 0.00 0.00 469.00 26 java 16:12:52 1000 884208 305.00 173.00 0.00 0.00 478.00 26 java 16:12:53 1000 884208 304.00 173.00 0.00 0.00 477.00 26 java 16:12:54 1000 884208 299.00 169.00 0.00 0.00 468.00 26 java 16:12:55 1000 884208 296.00 173.00 0.00 0.00 469.00 26 java 16:12:56 1000 884208 298.00 171.00 0.00 0.00 469.00 26 java 16:12:57 1000 884208 308.00 175.00 0.00 0.00 483.00 26 java 16:12:58 1000 884208 301.00 177.00 0.00 0.00 478.00 26 java 16:12:59 1000 884208 305.00 166.00 0.00 0.00 471.00 26 java 16:13:00 1000 884208 304.00 169.00 0.00 0.00 473.00 26 java 16:13:01 1000 884208 307.00 172.00 0.00 0.00 479.00 26 java 16:13:02 1000 884208 301.00 174.00 0.00 0.00 475.00 26 java but…​ the system is 60% idle\n$ vmstat 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 14 0 5254976 9665088 590824 4895220 0 0 0 0 50997 715648 25 16 59 0 0 16 0 5254976 9667204 590824 4895220 0 0 0 1372 50995 710429 24 16 60 0 0 15 0 5254976 9666244 590824 4895232 0 0 0 0 51544 707477 24 16 59 0 0 11 0 5254976 9664892 590872 4895160 0 0 0 980 51178 700680 24 16 60 0 0 14 0 5254976 9662968 590880 4895232 0 0 0 12 54800 710039 25 16 59 0 0 We still have a bottleneck outside of the application, most likely within mysql or we are still I/O bound!\nAt this point, we have a couple of options, we can either;\nA) tune MySQL/IO so that they are no longer the bottleneck or\nB) constrain that application below the maximum, such that the rest of the system is operating within it\u0026#39;s limits The easiest option is to simply constrain the application.\nImportant Choose your scaling methodology\nWe can either scale up or tune the system, or we can scale down the application to below the limits of the system.\nChoosing to scale up the system, or constrain the application, is a decision dependent on the goals of the testing.\nConstrain application We will remove the MySQL/System bottleneck by constraining the application to 4 cpu cores, therefore reducing the maximum load the application can drive to the database. We achieve this by running the application in docker;\n$ docker build -f ./src/main/docker/Dockerfile.jvm -t quarkus-project:0.1-SNAPSHOT . ... Successfully built 0cd0d50404ac Successfully tagged quarkus-project:0.1-SNAPSHOT $ docker run --network host --cpuset-cpus=0-3 quarkus-project:0.1-SNAPSHOT and re-running the test;\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 5.36ms 44.30ms 766.89ms 98.94% Req/Sec 9.50k 4.45k 15.37k 78.52% 1121692 requests in 1.00m, 220.06MB read Socket errors: connect 0, read 1, write 0, timeout 0 Non-2xx or 3xx responses: 1 Requests/sec: 18667.87 Transfer/sec: 3.66MB Ok, so we are not at Max Throughput, but we have removed the system outside of the application as a bottleneck. The bottleneck is NOW the application\nImportant Create an environment where the comparisons are valid\nBy constraining the application, we are not running at absolute Max Throughput possible, but we have created an environment that allows for comparisons between frameworks.\nWith a constrained application environment, we will not be in the situation where one or more frameworks are sustaining throughput levels that are at the limit of the system.\nIf any application is at the system limit, the results are invalid.\nAll network traffic is not equal! Further investigation showed that Quarkus is not running with TLS enabled between the application and database, so database network traffic is running un-encrypted. Let’s fix that;\nquarkus.datasource.reactive.url=${DB_URL:mysql://localhost:3306/baeldung?useSSL=false\u0026amp;tlsVersion=TLSv1.2} quarkus.datasource.reactive.max-size=95 quarkus.datasource.reactive.mysql.ssl-mode=required #\u0026#34;don\u0026#39;t do this in prod, don\u0026#39;t do this @ home, don\u0026#39;t do this !\u0026#34; #required for this test as mysql cert is self-signed quarkus.datasource.reactive.trust-all=true and re-run\n$ wrk -t2 -c10 -d1m -s ./post_zipcode.lua --timeout 2m -H \u0026#39;Host: localhost\u0026#39; http://localhost:8080 Running 1m test @ http://localhost:8080 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 2.44ms 12.94ms 354.67ms 98.17% Req/Sec 7.55k 3.55k 11.94k 77.93% 898541 requests in 1.00m, 176.26MB read Socket errors: connect 0, read 2, write 0, timeout 0 Non-2xx or 3xx responses: 2 Requests/sec: 14955.61 Transfer/sec: 2.93MB This provided us with a final, comparable throughput result of 14,955.61 req/sec\nImportant For comparisons, we need to ensure that each framework is performing the same work\nResults Is Quarkus really 600x times slower than Framework X/Y/Z? Of course not!\nOn my machine;\nthe initial result was 1.75 req/sec.\nfixing the application brought that up to 390.21 req/sec\nfixing some of the system bottlenecks gave us 25,599.85 req/sec\nconstraining the application, so that a fairer comparison with other frameworks can be made resulted in 18,667.87 req/sec\nand finally, enabling TLS encryption to the database gives a final result of 14,955.61 req/sec\nImportant Run 5 gives us our baseline for comparison, 14,955.61 req//sec Where does that leave Quarkus compared to Framework X/Y/Z? well…​ that is an exercise for the reader ;-)\nSummary Does these results show that Quarkus is quick? Well kinda, they hint at it, but there are still issues with the methodology that need resolving.\nHowever, when faced with a benchmark result, especially one that does not appear to make sense, there are a number of steps you can take to validate the result;\nFix the application: Are there errors? Is the test functioning as expected? If there are errors, resolve them\nEnsure the application is the bottleneck: What are the limiting factors for the test? Is the test CPU, Network I/O, Disk I/O bound?\nDo not stop evaluating the test when you see a \u0026#34;good\u0026#34; result. For comparisons, you need to ensure that every framework is the limiting factor for performance and not the system.\nChose how to constrain the application: either by scaling up the system, or scaling down the application.\nValidate that all frameworks are doing the same work. For comparisons, are the frameworks performing the same work?\nEnsure al frameworks are providing the same level of security. Are the semantics the same? e.g. same TLS encoding? same db transaction isolation levels?\nImportant The System Under Test includes the System. Do not automatically assume that your application is the bottleneck Notes on Methodology Caution Does this benchmark tell us everything we need to know about how Quarkus behaves under load? Not really! It gives us one data point\nIn order to have a meaningful understanding of behavior under load, the following issues with methodology needs to be addressed;\nLoad generation, database and application are all running on a single machine. The current test does not stress any of the network stack and there are side effects due to co-location of services. The application topology needs to be representative of a production environment.\nThis test does not measure application responsiveness from a users perspective. A tool that does not suffer from coordinated omissions, such as Hyperfoil, is required to accurately measure service response time, including system wait time. throughput != response time and response time is what matters to users!\nThe mixture of read/writes to the database changes throughout the duration of the test. Initially the load is very write heavy, as time progresses, the database load is predominantly read heavy. A more consistent pattern of read/writes should be maintained throughout the test duration.\nThe applications are not given time to correctly \u0026#34;warm up\u0026#34;, therefore the results are a mixture of Java code running in interpreted mode and compiled mode.\nDue to the issue above, it is not possible to derive how a framework would behave with real-world production traffic from this test\nAs with any benchmarking, it is always best to test a simulation of your production traffic\n","date":"2022-11-17T00:00:00Z","image":"http://example.org/post/reactive-crud-performance-a-case-study/apples-to-oranges_hu075406026e3cde1b9d53201b6232df5f_414123_120x120_fill_box_smart1_3.png","permalink":"http://example.org/post/reactive-crud-performance-a-case-study/","title":"Reactive CRUD Performance: A Case Study"},{"content":" Learn about Coordinated Omission, the root cause and its effects. After reading this post you should be able to answer questions such as \u0026#34;What is Coordinated Omission?\u0026#34;, \u0026#34;How does it effect benchmark results\u0026#34;, \u0026#34;How can we design a load test that does not suffer from coordinated omission\u0026#34; and \u0026#34;does my tool suffer from the coordinated omission problem?\u0026#34;\nTl;dr Coordinated Omission occurs when the load generator we choose is not able to accurately create a workload representative of real world traffic whilst load testing a remote service.\nThere is a \u0026#34;Coordination\u0026#34; from the System Under Test applying indirect back pressure to the load driver, that causes the load driver to \u0026#34;Omit\u0026#34; any number of valid results. The System Under Test can blocks the load generator, severely skewing it’s measurements.\nResponse time metrics measured with tools that suffer from Coordinated Omission are far from misleading, they are wrong. The worst part is, the load generator can not detect or inform users that the results are incorrect.\nUsing tools such as Hyperfoil, you can be sure that any response time metrics it captures are accurate; or, if it detects back-pressure from the System Under Test, it will record and report the unintended back-pressure.\nTell me about this Coordinated Omission thingy! Coordinated Omission is a term that has been in circulation for a while now. There are many articles that describe; for more detailed explanations of coordinated omission, please take a look at Further Reading.\nBefore exploring the nuances of coordinated omission, lets get clear in our minds what it is we are trying to do when we are measuring system \u0026#34;response time\u0026#34;.\nImagine a scenario where we run a call center for a building materials trade counter (Building Star Trade Supplies Inc)\nOur tag line is \u0026#34;Building Star Trade Supplies Inc: the best in the world for all your building supply needs!\u0026#34;\nTo improve customer experience, we want to reduce the time it takes for our customers to place an order. The faster customers can place an order, the happier they are, and the faster we can build a world beating business!\nWhat do we need to do; measure how long it takes to place a telephone order through our switchboard.\nIf it takes longer than 1 minute to place an order we will start to loose market share to our rivals Prime Materials Supplies.\nA typical interaction Typically a customer calls the call center, is put through to an operator, where the operator checks stock levels, raises a new order and confirms with the customer before terminating tha call.\nHow long does it take to place an order? There are 2 main components in the time taken to place the order;\nthe \u0026#34;Wait Time\u0026#34; the customer was being held in the switchboard queue before being put through the operator\nThe \u0026#34;Service Time\u0026#34; it took for the operator to process the customer request\nFrom the customers point-of-view, the total \u0026#34;Order Time\u0026#34; (i.e. the time taken to place the order) is ;\nImportant \u0026#34;Order Time\u0026#34; = \u0026#34;Wait Time\u0026#34; + \u0026#34;Service Time\u0026#34;\nTo measure the performance of our call center, we need to measure the total \u0026#34;Order Time\u0026#34;.\nIf it only takes a single operator 30 seconds to process an order request, but customers are waiting on average 30 minutes to be connected to them, the customer experience is poor\nWhat does a call center have to do with my Web Service?!? There are a lot of similarities between a call center and a Web Service.\nNote Any number of customers (clients) can call (tcp_socket::open) our switchboard (web service), where an operator (thread) will process the enquiry (request), interacting with multiple systems (backend services) before confirming an order (response) and terminating the call (tcp_socket::close).\nTypically for us developers of web services; before we push our changes into production, we want to know how it will scale or perform under sustained client load. So, we build a benchmark, take some measurements and deploy depending on if we see acceptable performance.\nBut how do we measure performance of a web service? What decisions do we take, and how does this impact our confidence in how our web service performs.\nMeasuring System performance So, you’ve been tasked with ensuring the application can handle production workload. The checklist typically looks something like;\n✓ pick a load generation tool\n✓ setup benchmarking environment\n✓ run load generation tool against test environment\n✓ ensure the system response times are within required SLA’s\n❏ ship it!\nImportant The first step is crucial! : Picking a load generation tool that models reality is vital in shipping a product that behaves they way you expecct it to\nModelling the real world Let’s go back to our Building Star Trade Supplies Inc. In order to improve customer experience, we have built a brand new call center BSTSI-callHandler-2.0!!\nWe have tested to make sure the call center works (functional testing); but before we start taking customers calls there, we need to ensure that it is more efficient (load testing) than BSTSI-callHandler-0.1.BETA.\nFor this work, we need to design a test that models the real world!\nDesigning the \u0026#34;load\u0026#34; test Our SLA for our call center stipulates that we need to be able to;\nProcess 20 orders per minute\nCustomers must spend on average less than 1 minutes on the phone placing an order.\n99% of customers should be able to place an order within 2 minutes\nSo, lets bring in a number of dummy customers (clients) that will ring the call center and place fictitious orders. We can measure how long it takes for each dummy customer to place and order.\nTo meet the SLA, we need to be able to process 20 orders per minute (throughput) with the average telephone call taking less than 1 minute (mean response time).\nFirst attempt Each tester is given their own phone and a list of orders to place\nThe tester calls the new call center and places an order\nAfter the call terminates, the tester checks the phone screen to see how long the call took\nCall durations are logged for each order\nAfter all the testers have run through their list of dummy orders. The call times for all the testers are collated\nAfter reviewing the call logs, we found the average call duration was 36 seconds. This within our SLA limit of 1 minute, SHIP IT!\nShip It!! Fairly soon after opening BSTSI-callHandler-2.0, negative reviews start appearing. Some people are frustrated that they can not quickly get through to place an order. And it is not just one person! there are a few disgruntled customers.\nWhat went wrong? Our test had some fundamental flaws. While everything appeared to provide us with the data to give us confidence about how the call center would perform, we were not quite modelling how calls would arrive in the real world.\nEach tester had been given their own phone and a list of orders to place. This puts some limits on the test;\nImportant Testers can only place one order at a time!\nTesters are blocked from placing any more orders until their current order is placed.\nIn the real world there are many more customers, each with their own phone\nIn the real world, customers enquiries arrive at different, random times, often in parallel.\nIn addition to to the test design problems above, in the real world there are hiccups. For example, in our call center there are Lunch breaks, fire alarms, computer systems crash etc.\nHow does a Hiccup effect our call center performance? We have our imaginary call center, now lets have an imaginary outage!\nFigure 1. https://dilbert.com/strip/1996-05-02 Someone in the server room has rolled over a network cable and accidentally severed it, finding a new cable and wiring the server back into the switch takes 10 mins. All the backend systems were out for 10 minutes, tying up the operators until the backend systems come back online.\nLets do some Math! Lets make some assumptions about our imaginary call center, with its imaginary outage;\ntesters will make 1,000 new orders.\nwe have 10 testers.\nthe call center should be handling 20 calls per minutes (i.e. 2x 30s calls per tester). The arrival rate is 20 calls per minute\nthe maximum call handle rate (max throughput) of the call center is 60 calls per minutes. I.e. the maximum processing rate is 60 calls per minutes\nany backlog does not effect the service time (in reality this is not true, but brevity we will making this assumption)\nour call center has a 10 minute hiccup in the middle of the test.\nall calls are processed, the dropout rate is 0\neach order takes a deterministic 30 seconds to complete. (service time = 0.5min)\nin the time before the outage, all calls are handled immediatley (waiting time = 0min)\nthe queue is a First-In-First-Out (FIFO) queue\nthe queue is infinitely sized\nWhat does this do the to summary statistics? A 10 minute Hiccup during our tests would have been observed like this by the testers;\nNote The Average Call Duration measured during Testing was 0.6 minutes (0min 36sec)\nWhereas, in reality, a 10 minutes Hiccup will be observed like this by our customers;\nNote The Average Call Duration experienced by customers was 1.9 minutes (1min 54s)\nIf you want to understand the math, please read Appendix A: Detailed Math\nWhy are the numbers so different? Important In our testing scenario, there were 10 testers who were blocked for 10 minutes. In reality users would keep calling the telephone line and being put on hold until an operator became available.\nOur test captured 10 Testers blocked for 10 minutes, but in reality 200 users would have been waiting for up to 10 minutes. We did not captured the waiting time of 200 of our users!\nOur flawed test showed the average order time of 36 seconds, but on average customers would have waited 1minute 54 seconds.\nThe MISSED waiting time was not included in the summary statistics!\nSecond Attempt Each tester is given multiple phones, a list of orders to place and the time to start the call and a stopwatch\nThe tester(s) calls the call center to place orders, at the time specified on their list\nIf the first call does not complete before the next order needs to be placed, the tester users a different phone to make the next call. Any one tester can have multiple calls running concurrently at the same time.\nAfter the call terminates, the tester checks the phone screen to see how the call took, and records this as the \u0026#34;Order Time\u0026#34;\nAfter all the testers have run through their list of dummy orders. The call times for all the testers are collated and summary data is calculated.\nIf the tester runs out of phones, they start the stopwatch and stop the stopwatch again when one of their phones becomes available. After all of the orders have been placed, the stopwatch value is recorded the total blocked time for each tester during the load test. This is a direct measurement of Coordinated Omission.\nWarning This time the average call time was 1 minute 20 seconds, above our SLA.\nWe need to investigate why we are not meeting our SLA before rolling out BSTSI-callHandler-2.0 to our customers\nWhat is different? Why is this a more accurate reflection of reality. A small number of testers are trying to mimic 1000 customer orders. In reality, we wouldn’t have 10 customers, each placing 100 orders in sequence. We are more likely to receive 1000 different customers, each placing one order. They would not arrive in sequence, but in parallel and at random times.\nIn the first test, the testers could only make one call and made the calls in sequence. The maximum queue size was the number of testers. If there was a hiccup, they could not start a new call, but were blocked until they could end their current call. The wait time of any other customers trying to call the call center was missed.\nIn the second test, the testers could use multiple phones to place calls in parallel. By have a list of pre determined times, we define how many new customers calls were arriving at the call center. We can record the total call time for each virtual customer, and if we run out of phones (connections) to support the arrival rate, we record the blocked time.\nImportant If there is any blocked time recorded, the results are invalid. It is invalid because we can no long queue any more customers, and record their wait time.\nBringing it back to Benchmark Design What can be done? A load generation tool that uses asynchronous I/O and uncouples threading from I/O, which measures timing independent on I/O is able to detect when the System Under Test is applying back-pressure to the load generator.\nTools such as Hyperfoil will detect and report server back-pressure, so you can be sure that the load generator is reporting accurate response times without any Coordinated Omission effects from the SUT.\nHow I tell if my load generation tool suffers from Coordinated Omission? Luckily there is a very simple test you can do! CTRL+Z\nWhile your benchmark is running, type CTRL+Z to Stop your process\n$ ./run_my_service.sh ^Z [1]+ Stopped ./run_my_service.sh After a period of time, start it again\n$ fg 1 ./run_my_service.sh Important If the load generator only reports N number of requests, equivalent to the number of threads configured to generate load, taking the Stopped period of time and no more threads experiencing delay then you have a problem\nSee it in action We covered a demonstration of Coordinated Omission in \u0026#34;Quarkus Insights #22: Performance Testing: Tips and Pitfalls\u0026#34;\nCan tune away this problem? What happens if I increase the number of threads? Unfortunately not, you might be able to mitigate some of the issues through tuning, but you can never be certain that the results are accurate. The fundamental problem is that there is missing data, but you can not tell from the results if all the data has been captured.\nStatements are often made such as \u0026#39;As with any Load Testing tool, if you don’t correctly size the number of threads, you will face the \u0026#34;Coordinated Omission\u0026#34; problem which can give you wrong or inaccurate results.\u0026#39; (https://jmeter.apache.org/usermanual/best-practices.html)\nThe fundamental issue is not with the size of the thread pool, but whether the load generator threads that measure response time can be blocked by the System Under Test.\nCan’t I just run the tests for longer? How many hiccups does your system have? How long do they last? Even if you can quantify those metrics, adjusting adding wait time to response times through a different data source is error prone. You might as well pick a load generation tool that handles coordinated omission and not have to normalize for a broken methodology.\nMy application does not stop that long, surely this is effect negligible? I have personally witnessed applications under load fully paused for 2-3 seconds to perform GC, every 5-10 seconds. Unless your load generator can measure that wait time, you will not know that the application was stalled. a load generator that suffers from co-rdinated omission has no way of measuring it\nCan’t I just look at the summary stats to tell if my run was affected? It is very difficult! The maximum values will be the same. The mean and centile response times look sensible. The only way to tell is if the requests sent are equal to expected number of requests to be sent during the time period. However, if you can not set an arrival rate, it is not possible to determine if the expected number of requests were sent.\nImportant If the load generation tool does not decouple time measurement from generating load, the problem can not be tuned away.\nSummary Coordinated Omission is the unintended back pressure a system under test can apply to a load generation tool, that prevents that tool for accurately recording user experience.\nResponse time = wait time + service time. A load generation tool that suffers from coordinated omission will only record service time and will fail to record wait time. Wait time can be significant and therefore can have a huge effect on summary statistics.\nThe worst part is, the load generator is unable to record the missed time, so users are completely unaware that there is a problem.\nIn order to design response time tests (typically associated with SLA’s) we need to use tools that accurately record response time, including wait time. More importantly, our tools should warn us if there is any unintended back-pressure from the System Under Test.\nChoosing a tool such as Hyperfoil will not only provide you with accurate measurements, it will also warn you and fail the benchmark if it detects hiccups that have effected the accuracy of the results.\nFurther Reading For more information, please visit the following articles;\nhttp://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html\nAppendix A: Detailed Math In our test scenario we had 10 testers placing orders each placing an order. At 6 mins there was an outage, that lasted 10 minutes.\nTherefore, for 10 blocked orders;\nthere was a wait time of 10 minutes each\nthere was a service time of 0.5 mins\ntotal order time was 10.5 minutes\nFor the remaining 990 orders;\nthere was a wait time of 0 minutes each\nthere was a service time of 0.5 mins\ntotal order time was 0.5 minutes\nNote The Average Call Duration measured during Testing was 0.6 minutes\nIn the Real World Things are a bit more complicated;\nnew customers arrive at a rate of 20 per minute\ntherefore, during the first minute of outage, 20 customers will be placed in the switchboard queue and will have to wait for 10 minutes, before the queue starts to empty\nin the 2nd minute of the outage another 20 customer arrive, are placed in the switchboard queue and will have to wait for 9 minutes, before the queue starts to empty\ncustomers continue to arrive during the outage, filling up the switchboard queue\nonce the outage is resolved the operators can start to process the queue of customers. But there is a maximum number of customers they can process in one minutes (60 customers per minute max throughput)\nwhile the backlog is being processed at a rate of 60 customers per minute, 20 customers per minute are still being added to the back of the queue.\nDuring the outage, the total Wait time can be modelled by;\nAfter the outage, while the backlog is cleared, the total Wait time can be modelled by;\nIf we calculate our scenario;\nNote The Average call duration experienced by customers was 1.9 minutes!\n","date":"2022-11-16T00:00:00Z","image":"http://example.org/post/coordinated-omission/coordinated-omission-cumulative-wait-time_hu97636a6d6452f8d98e3a591576d9d311_212721_120x120_fill_box_smart1_3.png","permalink":"http://example.org/post/coordinated-omission/","title":"Coordinated Omission"}]